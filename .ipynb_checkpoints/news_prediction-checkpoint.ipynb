{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERSION 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm going to make a fake news predictor, and you are going to join me on my journey trying to solve one of humanities most difficult challenges. \n",
    "#### So, fake news has been around since before 'news' became a thing. But I want to tackle this issue, and try to contribute to saving democracy while preserving our rights to freedom of speech!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the packages that we're going to need throughout our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Modelling & Prediction \n",
    "import nltk as nltk\n",
    "import re\n",
    "from datetime import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "sns.set(color_codes = True)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore fake news dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first load the fake news dataset then run info function to have a look at the dataset and its content. You can see that there's 23481 rows and 5 columns in total. All columns has 'object' as type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fakeNewsData = pd.read_csv('data/Fake.csv', parse_dates=['date'])\n",
    "fakeNewsData['label'] =  'fake'\n",
    "fakeNewsData.info()\n",
    "fakeNewsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert date column to datetime type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hhhmmm, the date column looks kind of funny. Let's have a closer look at it. First, I tried to convert date column to date and ran into an issue i didnt noticed before. \n",
    "\n",
    "###### Below is the error: ParserError: Unknown string format: https://100percentfedup.com/served-roy-moore-vietnamletter-veteran-sets-record-straight-honorable-decent-respectable-patriotic-commander-soldier/\n",
    "\n",
    "There's a link in the date column. HOW? That we don't know. I did the following to select only the rows that are actually date values.\n",
    "So, i tried to convert the date column to date with an extra parameter this time, I used error is coerce. \n",
    "\n",
    "What this does is it parse the string to NaT. Doing this we will convert the string dates to actual date types and strings that are not date values will be set as NaT. This will help us to filter/select only the date values to take into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeNewsData['date'] = pd.to_datetime(fakeNewsData['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see the rows that are not of date type. 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeNewsData.date[fakeNewsData.date.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will selct only the rows that are of dae type into our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeNewsData = fakeNewsData[fakeNewsData['date'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see in the table and the list above that the date column has some issues compared to the true news date column. There's a link in the date column... huh? We don't want that. So, lets remove the links from the date column and convert the column to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fakeNewsData = fakeNewsData[fakeNewsData.date.str.contains(\"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\")] # get only string that contains the months\n",
    "# fakeNewsData['date'] = pd.to_datetime(fakeNewsData['date'], format='%Y-%m-%d') # convert column to datetime\n",
    "fakeNewsData.info()\n",
    "fakeNewsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that date columns is datetime type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore the true dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the true news dataset then run info function to have a look at the dataset. \n",
    "You can see that there's 21417  rows and 5 columns in total. All columns has 'object' as type, except for the date column which is of datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trueNewsData = pd.read_csv('data/True.csv', parse_dates=['date'])\n",
    "trueNewsData['label'] = 'true'\n",
    "trueNewsData.info()\n",
    "trueNewsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert date column to datetime type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the date column in already converted to date type. But still, let's make sure there's no mistakes like the fake news dataset.\n",
    "\n",
    "Let's run the same steps we did with the fake news dataset. Convert column to date type and add parameter error as coerce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueNewsData['date'] = pd.to_datetime(trueNewsData['date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's return the NaT values.\n",
    "\n",
    "Fortunately, there are no wrong values in the true news date column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trueNewsData.date[trueNewsData.date.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combined the datasets! And return the shape to ssee how many rows and columns are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concantenate the datasets, why? \n",
    "# Both datasets are very similar in terms of the columns. \n",
    "# Since their identical, we can't make a join on a column.\n",
    "newsData = pd.concat([fakeNewsData, trueNewsData], ignore_index=True) # fakeNewsData.join(trueNewsData, how='outer', lsuffix=\"_left\", rsuffix=\"_right\")\n",
    "\n",
    "# combine title and text to create a new column, news.\n",
    "newsData['news'] = newsData['title'] + newsData['text']\n",
    "\n",
    "# drop the title and text columns since they are not needed anymore.\n",
    "newsData = newsData.drop(['title', 'text'], axis=1)\n",
    "\n",
    "# # re-arrange the combined dataset columns\n",
    "newsData = newsData.reindex(columns=['news', 'subject', 'date', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the shape of our combined data. You will notice that there's over 44k rows and 4 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how the labels are distributed. You can see that fake news is more occurent than the true news. More fake articles than true/real articles. However, they are still fairly balanced I would say. Both are above the 20K. You agree? Of course you do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = newsData['label']\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(target_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot subjects by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.countplot(x ='subject', hue= 'label', data = newsData)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Fake/True news subject')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the subjects. You can see that there's some ambigous columns. For exmple, for the fake dataset \"government news\" and \"politics\" basically has the same meaning and what about \"news\" what type of news is it? It could be anything from my point of view.\n",
    "Furthermore, \"politics news\" and \"world news\" has rows of more than 10k each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning news data in the news column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of useless words in the dataset, and that's not good for our algorithm when it's time to predict. What should we do? Let's clean it up! We'll do that in a few steps. First we will remove all punctuation from the news column then we will remove the stop words. Stop words are words such as the, a, an, in, and more. So, this way only the important words will be used by our algorithm to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(word):\n",
    "#     word = str(word).lower() # set all to lowercase\n",
    "    word = re.sub(r'[^\\w\\s]', '', word) # remove punctuation\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lambda function here to apply the clean_data() to the news column\n",
    "# use axis 0 to apply function to each column and axis 1 to apply function to each row.\n",
    "newsData.news = newsData.news.apply(lambda x:clean_data(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling the clean_data(), let's have a look at the dataframe. Immediately, you can see the clear difference (btw the difference is in the news column). There's no commas, or dots, or brackets, none of that. ALL GONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we're going to remove stop words. To have a more clearer visual of what happened, let's return the length of characters in the first row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the length is 2849. Now let's remove the stop words then have a look at the length again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newsData.news.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsData.news = newsData.news.apply(lambda x: ' '.join([w for w in x.split() if w not in stop_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the stop words, you can see a difference in the length of characters in the first row. Removing stop words makes it easier for our algorithm to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newsData.news.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our news data looks better and ready for prediction, let's plot a word cloud to have a visualization of the most frequent words in news that's labeled as fake news. \n",
    "\n",
    "But this one might be a bit more advance. You're probably wondering why, that's a good question. The words we are going to plot in the word cloud are the 50 most common words in the fake news. This is done by using collections Counter. This class is very useful to count the frequency of elements in an iterable. It is a collection where elements are stored as dictionary keys and their counts are stored as dictionary values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use counter on news labeled as fake news to return the most common 100 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Counter(\" \".join(newsData[newsData['label'] == 'fake']['news']).split()).most_common(100)\n",
    "wordcloud = WordCloud(width=1000, height=500, background_color = 'black', stopwords = stop_words).generate(str(text))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(40,40))\n",
    "plt.imshow( wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the most frequent words are US, Trump, President, State, Clinton and more. So, as i said in the project proposal the prediction will be biased and will not perform well with other types of news because it's being trained and tested on world news, and american news (regarding the 2016 election). \n",
    "However, as our we modify our algorithm and tune it, we can have it predict all types of news. But for now, let's use this dataset just to see how well it predicts fake news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# newsData.news = newsData.news.apply(lambda x: [word_tokenize(x)])\n",
    "# newsData.news = newsData.news.apply(lambda b: ' '.join([lemmatizer.lemmatize(u) for u in b.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = newsData.label\n",
    "X = newsData.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all the boring stuff is done, let's get to work. In the next part i will show you how we're going to split our dataset into train and test sets!\n",
    "We're going to use 30% of our data for testing set with a random state of 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify = y)\n",
    "\n",
    "# X_train, y_train, X_test, y_test = train_test_split(X, y, test_size=0.33, random_state=53)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting the data, we can see that X has a shape of 31421 values and y with 13467 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_train = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = count_vectorizer.transform(X_test)\n",
    "count_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_vectorizer.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
    "nb_classifier = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "# gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the predicted tags: pred\n",
    "pred = nb_classifier.predict(count_test)\n",
    "# y_pred = gnb.predict(count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy score: score\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"Multinomial Naive Bayes model accuracy(in %):\", score * 100)\n",
    "# print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "\n",
    "# Calculate the confusion matrix: cm\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, pred, labels=['fake', 'true']).ravel()\n",
    "print('True negative:',tn, ' - ', 'False positive:', fp, ' - ', 'False negative:', fn, ' - ', 'True positive:', tp)\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, pred, labels=['fake', 'true'])\n",
    "labels = ['fake', 'true'] \n",
    "\n",
    "fig = plt.figure() \n",
    "\n",
    "ax = fig.add_subplot(111) \n",
    "\n",
    "cax = ax.matshow(cm) \n",
    "\n",
    "plt.title('Confusion matrix of the classifier') \n",
    "\n",
    "fig.colorbar(cax) \n",
    "\n",
    "ax.set_xticklabels([''] + labels) \n",
    "\n",
    "ax.set_yticklabels([''] + labels) \n",
    "\n",
    "plt.xlabel('Predicted') \n",
    "\n",
    "plt.ylabel('True') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { 'C':[0.1,1,100,1000],'kernel':['rbf','poly','sigmoid','linear'],'degree':[1,2,3,4,5,6],'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "gridSC = GridSearchCV(SVC(),param_grid)\n",
    "gridSC.fit(count_train, y_train)\n",
    "print(gridSC.best_score_)\n",
    "print(gridSC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = gridSC.predict(count_test)\n",
    "print(\"Accuracy in percentage:\", metrics.accuracy_score(y_test, grid_predictions)*100)\n",
    "print(classification_report(y_test, grid_predictions,  labels=np.unique(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nb_classifier_pickle', 'wb') as file:\n",
    "    pickle.dump(nb_classifier, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model and run application to get prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('nb_classifier_pickle', 'rb') as file:\n",
    "#     model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statement = {'House Democrats rally to protect Special Counsel Mueller'} # House Democrats rally to protect Special Counsel Mueller barack obama is running for president in 2016\n",
    "# len(statement)\n",
    "\n",
    "# # statement = eval(input(\"Enter news:\"))\n",
    "# # print(\"You entered: \" + str(statement))\n",
    "\n",
    "# def fakenews(statement):\n",
    "#     load_model = pickle.load(open('nb_classifier_pickle', 'rb'))\n",
    "#     count_pred = count_vectorizer.transform(statement)\n",
    "#     prediction = load_model.predict(count_pred)\n",
    "    \n",
    "#     return (print(\"The statement is: \", prediction))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# #     statement = statement.values #.reshape(-1, 1)\n",
    "# #     statement = [x for x in statement]\n",
    "# #     print(statement)\n",
    "#     fakenews(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
